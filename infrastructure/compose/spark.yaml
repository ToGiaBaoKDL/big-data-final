x-spark-common: &spark-common
  build:
    context: ../../
    dockerfile: infrastructure/docker/spark/Dockerfile
    args:
      SPARK_TAG: ${SPARK_TAG:-3.5.8}
  user: root
  networks:
    - data-network
  volumes:
    - ../../processing/spark:/opt/spark/jobs
    - ../../data:/opt/spark/data
  environment:
    - SPARK_HOME=/opt/spark

services:
  spark-master:
    <<: *spark-common
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.master.Master
    deploy:
      resources:
        limits:
          memory: ${SPARK_MASTER_MEM_LIMIT:-2G}
    ports:
      - "9090:8080"
      - "7077:7077"
    environment:
      - SPARK_MODE=master
      - SPARK_EVENTLOG_ENABLED=true
      - SPARK_EVENTLOG_DIR=s3a://${MINIO_BUCKET_LOGS:-dl-logs-3e91b5}/spark-events/
      - SPARK_HISTORY_FS_LOGDIRECTORY=s3a://${MINIO_BUCKET_LOGS:-dl-logs-3e91b5}/spark-events/

  spark-worker:
    <<: *spark-common
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
    depends_on:
      - spark-master
    deploy:
      replicas: 2
      resources:
        limits:
          cpus: '${SPARK_WORKER_CPU_LIMIT:-1.0}'
          memory: ${SPARK_WORKER_MEM_LIMIT:-2G}
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=${SPARK_WORKER_MEMORY:-2G}
      - SPARK_WORKER_CORES=${SPARK_WORKER_CORES:-2}
      - SPARK_EVENTLOG_ENABLED=true
      - SPARK_EVENTLOG_DIR=s3a://${MINIO_BUCKET_LOGS:-dl-logs-3e91b5}/spark-events/
      - SPARK_HISTORY_FS_LOGDIRECTORY=s3a://${MINIO_BUCKET_LOGS:-dl-logs-3e91b5}/spark-events/
      - SPARK_HADOOP_fs_s3a_impl=org.apache.hadoop.fs.s3a.S3AFileSystem
      - SPARK_HADOOP_fs_s3a_path_style_access=true

  spark-history-server:
    <<: *spark-common
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.history.HistoryServer
    depends_on:
      - spark-master
      - minio
    ports:
      - "18080:18080"
    env_file:
      - ../.env
    environment:
      - SPARK_HISTORY_OPTS=-Dspark.history.fs.logDirectory=s3a://${MINIO_BUCKET_LOGS:-dl-logs-3e91b5}/spark-events/
      - SPARK_HADOOP_fs_s3a_endpoint=http://minio:9000
      - SPARK_HADOOP_fs_s3a_access_key=${MINIO_ROOT_USER}
      - SPARK_HADOOP_fs_s3a_secret_key=${MINIO_ROOT_PASSWORD}
      - SPARK_HADOOP_fs_s3a_path_style_access=true
      - SPARK_HADOOP_fs_s3a_impl=org.apache.hadoop.fs.s3a.S3AFileSystem
      - AWS_ACCESS_KEY_ID=${MINIO_ROOT_USER}
      - AWS_SECRET_ACCESS_KEY=${MINIO_ROOT_PASSWORD}
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:18080"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
